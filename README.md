# ğŸ§  Dual-Path Explainable AI Dashboard for Alzheimerâ€™s Diagnosis

A modular AI framework for early diagnosis of **Alzheimerâ€™s Disease (AD)** using dual-path analysis of structured clinical data and MRI scans. The system provides interpretable predictions through an interactive Streamlit dashboard powered by **SHAP** and **CAM** visualizations.

---
## ğŸ“– Overview

This project integrates **machine learning** and **deep learning** approaches into a single explainable framework:

### ğŸ”¬ Clinical Data Path
- Machine learningâ€“based predictions from structured patient data  
- **SHAP explainability** for global and individual feature importance  
- Patient comparison and **what-if analysis** for sensitivity testing  

### ğŸ§¬ MRI Image Path
- Deep learning predictions using **InceptionV3 transfer learning**  
- **Score-CAM** highlighting discriminative brain regions  
- Robust computer vision pipeline for neuroimaging analysis  

### ğŸ“Š Interactive Dashboards
- Real-time upload: CSV (clinical data) / MRI scans (images)  
- Predictions with explainability and patient-specific recommendations  
- Persistent data storage with **SQLite database**  
- Modular navigation: Home, Upload, Clinical Dashboard, MRI Dashboard  

---
## ğŸ“‚ Dataset Download
Before running the pipelines, download the datasets from Kaggle:
- **Clinical Dataset (CSV)** -> https://www.kaggle.com/datasets/rabieelkharoua/alzheimers-disease-dataset 
- **MRI Dataset (Images)** -> https://www.kaggle.com/datasets/muhammadbakhsh277/balanced-dataset-of-alzheimers-disease 

---
## ğŸš€ Key Features
- âœ¨ **Dual-Modal Analysis** â€” Clinical + MRI independent pipelines  
- ğŸ” **Explainable AI** â€” SHAP (clinical) + CAM (MRI)  
- ğŸ“± **Interactive Dashboard** â€” Streamlit-based web app  
- ğŸ§ª **What-If Analysis** â€” Adjust features, test prediction sensitivity  
- ğŸ’¾ **Persistent Storage** â€” Centralized SQLite database  
- ğŸ¥ **Clinical Integration** â€” Patient-level insights + recommendations  

---
## ğŸ“‹ Prerequisites
- Python **3.10+**  
- Virtual environment recommended  

---
## âš™ï¸ Installation

Install dependencies:

pip install -r requirements.txt

---
## âš™ï¸ Configuration

Update the input/output paths in the respective files before running.

**Clinical Classification (`Alzheimer_Clinical_BinaryClassification.ipynb`)** 

input_path = "/path/to/alzheimers_disease_data.csv"
output_folder = "/path/to/alzheimers_model_files"

**MRI Classification (`Alzheimer_MRIImage_MultiClassification.ipynb`)**

DATA_DIR = "/path/to/MRI_Image_Data"
OUTPUT_DIR = "/path/to/output_results"

**Database (`alzheimers_db_setup.py`)**

base_dir = "/path/to/alzheimer_predictions.db"

**Dashboard Upload Page (`uploaddatapage.py`)**

CSV_MODEL_FOLDER = "/path/to/alzheimers_model_files"
IMAGE_MODEL_FOLDER = "/path/to/alzheimer_model_4class.keras"
SHAP_UTILITY_PATH = "/path/to/shap_utils.py"
SCORECAM_PATH = "/path/to/scorecam.py"

**Clinical Dashboard (`ClinicalDashboardPage.py`)**

model_folder = "/path/to/alzheimers_model_files"

**MRI Dashboard (`MRIDashboardPage.py`)**

sys.path.append("/path/to/project/root")

---
### ğŸƒâ€â™‚ï¸ Usage

**Database Setup**

python alzheimers_db_setup.py

**Train Models (Jupyter Notebooks)**

jupyter notebook Alzheimer_Clinical_BinaryClassification.ipynb
jupyter notebook Alzheimer_MRIImage_MultiClassification.ipynb

**Launch Dashboard**

streamlit run homepage.py

**Navigate Dashboard**

Homepage â†’ Project overview

Upload Page â†’ Upload clinical CSV or MRI images

Clinical Dashboard â†’ Predictions + SHAP analysis

MRI Dashboard â†’ Predictions + ScoreCAM visualizations

---
### ğŸ“‚ Project Structure

alzheimer-ai-dashboard/
â”‚
â”œâ”€â”€ ğŸ“Š Jupyter Notebooks (Development & Training)
â”‚   â”œâ”€â”€ Alzheimer_Clinical_BinaryClassification.ipynb    # Clinical ML pipeline
â”‚   â””â”€â”€ Alzheimer_MRIImage_MultiClassification.ipynb     # MRI CNN pipeline
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ Streamlit Dashboard Components
â”‚   â”œâ”€â”€ homepage.py                                     # Landing page
â”‚   â”œâ”€â”€ pages/
â”‚       â”œâ”€â”€ uploaddataPage.py                               # File upload interface
â”‚       â”œâ”€â”€ ClinicalDashboardPage.py                        # Clinical predictions & SHAP
â”‚       â””â”€â”€ MRIDashboard.py                                 # MRI predictions & CAM
â”‚
â”œâ”€â”€ ğŸ”§ Core Utilities & Processing
â”‚   â”œâ”€â”€ alzheimers_db_setup.py                          # Database setup & operations
â”‚   â”œâ”€â”€ shap_utils.py                                   # SHAP explainability utilities
â”‚   â”œâ”€â”€ scorecam.py                                     # Score-CAM/Grad-CAM utilities
â”‚   â”œâ”€â”€ clinical_explanations.py                       # Clinical recommendations
â”‚   â””â”€â”€ style.py                                        # Dashboard styling
â”‚
â”œâ”€â”€ ğŸ“‚ Data Files
â”‚   â”œâ”€â”€ alzheimers_disease_data.csv                     # Clinical training dataset
â”‚   â””â”€â”€ MRI_Image_Data/                                 # MRI image dataset
â”‚       â”œâ”€â”€ MildDemented/
â”‚       â”œâ”€â”€ ModerateDemented/
â”‚       â”œâ”€â”€ NonDemented/
â”‚       â””â”€â”€ VeryMildDemented/
â”‚
â”œâ”€â”€ ğŸ“¦ Configuration
â”‚   â”œâ”€â”€ requirements.txt                                # Python dependencies
â”‚   â””â”€â”€ README.md                                       # Project documentation
â”‚
â””â”€â”€ ğŸ¤– Generated Models (After Training)
    â”œâ”€â”€ /alzheimers_model_files/                        # Clinical model storage
    â””â”€â”€ /output_results/                                # MRI model outputs

---
### ğŸ“Œ Notes

Update all hardcoded file paths before deployment.

Models and data can be stored locally or hosted (e.g., GitHub LFS, Google Drive).

SQLite ensures all predictions and interpretability results are tracked.